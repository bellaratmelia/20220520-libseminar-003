{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a163a3-0a1b-45aa-a1ac-2defcbc59dfe",
   "metadata": {},
   "source": [
    "# Learning Objectives:\n",
    "\n",
    "By the end of this session, participants should be able to:\n",
    "\n",
    "* Use Panda’s DataFrame for basic data wrangling\n",
    "* Use Scipy/Numpy to conduct descriptive stats and t-test\n",
    "* Create a simple visualization of data using Seaborn\n",
    "* Describe how API works\n",
    "* Use BeautifulSoup to scrape data from a web page\n",
    "* Use NLTK for basic data pre-processing and word count\n",
    "* Describe how to use GitHub publish their code repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb8610-e7f4-4c61-b629-8353c03f1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5b8ec-49e8-44c5-9cfb-8ddc79ae98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq \n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d240da-c843-4f37-8189-03a16e8e8456",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataframe 101 (60 minutes)\n",
    "- reading from csv\n",
    "- describe and info\n",
    "- rename columns\n",
    "- slicing data\n",
    "- filtering data, group by\n",
    "- counting values\n",
    "- simple plots\n",
    "- deriving new columns, dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a566146-daa1-4d0e-acb6-5c67615f2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from CSV\n",
    "# youth-survey.csv consists of responses from youths (15-30 years old) in Czech Republic \n",
    "data = pd.read_csv('youth-survey.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422bd304-a7aa-4e6f-a513-fd6b2e9af561",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieve basic info about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c08c07-0838-4eee-ac9c-3362af79965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DataFrame.info() method to find out more about a dataframe.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba641fb7-b159-4430-a704-78b108eb80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataFrame.columns variable stores information about the dataframe’s columns.\n",
    "# This one doesn't have parentheses because it's not a function, but a \n",
    "# variable inside the dataframe object (member variable)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba581374-fe0a-4817-abcc-ba95d314acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly get the number of rows and columns of the dataframe\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b3c5f-0081-482f-bff9-56a77dd0a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.describe() gets the summary statistics of the columns that have numerical data. \n",
    "# All other columns are ignored, unless you use the argument include='all'.\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e5ace-b0b3-4bdf-912d-6962c43dedec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a341609-ec60-4709-a114-58393ddc7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes column names need to be renamed to mae it easier for us\n",
    "# rename columns to be all lowercaps with no whitespace (replace whitespace with hyphen)\n",
    "# rename them to something more meaningful\n",
    "\n",
    "data.rename(columns = {\n",
    "    \"Energy levels\": \"energy-levels\",\n",
    "    \"Internet usage\": \"internet-usage\",\n",
    "    \"Loneliness\": \"loneliness\",\n",
    "    \"left - right\" : \"dominant-hand\",\n",
    "    \"Village - town\": \"locality\"\n",
    "}, inplace=True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98049528-f6c5-4ec0-b1ca-582a2cab06b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Selecting a subset of dataframe (\"slicing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dfac8-acce-4bb3-b757-9d06f1361328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a subset (\"slicing\") \n",
    "# get the age of participants\n",
    "data[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbdbd7-0efd-4d80-af9c-0bc2e6fa0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe just a column\n",
    "data[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dda0be-ac94-4cb5-bce2-8f4035b70301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the height and age of participants\n",
    "data[[\"height\", \"age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a104a0-c763-4127-b0b8-8011c512adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the two columns\n",
    "data[[\"height\", \"age\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74413c-1ec8-4bc9-97b4-4e556a02a28f",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Get the loneliness, happiness, and energy-levels columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c8db1-03d8-4091-8bca-dffabe98a76e",
   "metadata": {},
   "source": [
    "### Filtering the data to fit specified criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064e8b4-fb3b-45ee-9575-f085c3e0e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering: Get all data from participants above 18 years old\n",
    "criteria = data[\"age\"] > 18\n",
    "data_above_18 = data[criteria]\n",
    "\n",
    "data_above_18.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463585e-ced7-4e71-b183-d822ce2dd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from Female participants above 18 years old\n",
    "criteria = (data[\"age\"] > 18) & (data[\"gender\"] == \"female\")\n",
    "data_female_18 = data[criteria]\n",
    "\n",
    "data_female_18.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d30f76-73de-421b-ac54-817da01029bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get participants that stated their age\n",
    "criteria = data[\"age\"].notna()\n",
    "data_age_known = data[criteria]\n",
    "\n",
    "data_age_known.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65b9e6-32bd-4acc-ad57-83a452881a86",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Get data from people whose happiness ratings are >= 3 or loneliness rating <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c4b85-176d-4b81-8df5-b07ea277acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even more granular filtering:\n",
    "# get the internet-usage information of city-dwelling participants\n",
    "\n",
    "# we can of course do it in two steps: filter the row based on the locality, and then slice the internet-usage column\n",
    "# using .loc, we can filter both criteria at one go\n",
    "\n",
    "criteria = (data[\"locality\"] == \"city\")\n",
    "city_dwellers_internet_usage = data.loc[criteria, \"internet-usage\"]\n",
    "\n",
    "city_dwellers_internet_usage.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77237b0-c079-48d4-9ae3-db7ab2004be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve based on index number instead of column names or row values\n",
    "# retrieve the first 3 rows only\n",
    "\n",
    "data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e108c-3f1d-4a8e-af49-e1d3f0381524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve \"lying\" values (2nd column) of row 5 to 10\n",
    "# use .iloc to perform this filtering+slicing in one go\n",
    "\n",
    "data.iloc[5:11, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628b142-8ea8-48f3-b719-b17721b29b6c",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Get the happiness and loneliness rating of participants with more than 1 siblings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c7bb8-aae8-4b6c-a5be-a1bd355718be",
   "metadata": {},
   "source": [
    "### Updating values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63129e-1eb2-4e70-b452-7a054c69e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also update the values in dataframe, especially for the empty ones\n",
    "# update the missing siblings value to 0\n",
    "# inplace = True so that the changes are applied to the dataframe itself\n",
    "\n",
    "data[\"siblings\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c552d30e-c1eb-4a9a-aeed-1e23db2a516f",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Update the missing values in gender to \"No Gender\"\n",
    "* Update the the values \"left handed\" to \"l\" and right handed to \"r\" (hint: you can use .loc for this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c9b87-e68b-45ad-b19c-80d639fb6542",
   "metadata": {},
   "source": [
    "### Counting and Sorting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a76026-bc0f-4e4a-8aac-01bdeb047ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out how many participants are female or male\n",
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b30650-73fa-4137-8aee-610b9113de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out how many participants are female or male from villages and towns\n",
    "data[[\"gender\", \"locality\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c584bf-686d-4319-aed3-f00792e3b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the age of participants from youngest to oldest\n",
    "data.sort_values(by='age', inplace=True)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd26a8b-2a9c-493a-8a8b-cc0fe815ed43",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Include the NaN value when counting the number of female and male participants\n",
    "* Sort participants based on happiness rating, from highest to lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38702f-a110-4781-90e6-463ea59baf96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating new column based on other columns, dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42acbe4e-e97d-4a4b-a7c3-c6df42dc8b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called \"height-in-m\", deriving from the \"height\" column\n",
    "data[\"height-in-m\"] = data[\"height\"] / 100 # no need to use loops as dataframe will perform this automatically to all values in the column\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b21934-5da1-4808-8fe5-052dd8abc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a column\n",
    "data.drop(columns=[\"height-in-m\"], inplace=True)\n",
    "# inplace=True means apply the change to the current dataframe\n",
    "\n",
    "#check the columns now\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bfc9b-cf54-4e82-a74e-411a34bdb992",
   "metadata": {},
   "source": [
    "### Simple plots with Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e323d1-c7f8-4d42-a85f-5e5e492e6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# create a histogram for Energy Levels data\n",
    "sns.displot(data[\"energy-levels\"], discrete=True, shrink=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0982ad4-7a77-46c3-873b-9d443e504de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also create a scatterplot\n",
    "sns.stripplot(x=\"punctuality\", y=\"age\", data=data, hue=\"punctuality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638d964-188e-418b-a6c3-12e688df3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"happiness\", data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f6f68-bc09-4798-8580-11d8c6b6bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"happiness\", hue=\"locality\", data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bd2a0-dd2e-43dc-91d2-618bfd093c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stats with Dataframe\n",
    "\n",
    "- mean, mode, median, std, etc\n",
    "- correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dba5a6-27a9-402e-bd57-78b4e26fef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average age of the participant\n",
    "data[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e133e40-797d-462e-bd91-14bab101d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median age of the participant\n",
    "data[\"age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9506d81-9810-4c73-a7c2-de3978f8587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the most common age among participants?\n",
    "data[\"age\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271c370-e14b-41d5-bc81-55f8f76c494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the average age of female and male participants?\n",
    "grouped_data = data.groupby(by=[\"gender\"]).mean()\n",
    "grouped_data[\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10994577-4a93-4dc3-b8b3-8f6699a7bbf9",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Find out the average loneliness rating of participants grouped by their gender and locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096e8ad-43cf-4551-b86a-b3df4502469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### inferential stats ####\n",
    "# are there any relationship between these two variables?\n",
    "# let's check the value for pearson's r\n",
    "pearson = data[\"happiness\"].corr(data[\"age\"])\n",
    "pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0827d4-8001-4cb8-9952-1da0b54398a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the p-value, we can use scipy's spearmanr function\n",
    "from scipy import stats\n",
    "\n",
    "# the data has some NaN values, let's replace them with 0\n",
    "data[\"happiness\"].fillna(0, inplace = True)\n",
    "data[\"age\"].fillna(0, inplace = True)\n",
    "\n",
    "spearman = stats.spearmanr(data[\"happiness\"], data[\"age\"])\n",
    "spearman\n",
    "# first value is the coefficient, and the second value is the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06988c6-5128-4349-b022-06ffc5f8db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also quickly calculate the correlation coefficient between numerical variables\n",
    "# and keep them in a matrix\n",
    "corr_matrix = data.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d186453-f13a-4ca7-81c7-ac626ec0a4b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show the matrix in a heatmap using seaborn\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f03a4-3fc3-4e2c-8886-08c091d139e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## API and Web scraping (50 Mins + 5 mins break)\n",
    "\n",
    "* API calls in Python (20 Minutes)\n",
    "** URL for CORE API: https://api.core.ac.uk/v3/search/works/?q=singapore+language.code:en+yearPublished%3E2015\n",
    "* Simple web-scraping (30 Minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b4929-84ed-4bbf-8fe4-4e3e9b0656e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use CORE API to retrieve articles in CORE about Singapore, published after 2015.\n",
    "\n",
    "* brief lecture on anatomy of API --> e.g. for retrieving a single paper using its DOI\n",
    "* how to read API documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a782820-c7f0-4c0e-a441-28b0a4ac8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the apikey and prepare the api call\n",
    "with open(\"apikey.txt\") as f:\n",
    "    api_key = f.read()\n",
    "    \n",
    "api_call = \"https://api.core.ac.uk/v3/search/works/?q=singapore+language.code:en+yearPublished%3E2015&api_key=\" + api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe98bf-64e8-4870-bc0c-f45780485327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the API take a peek on the response in JSON format\n",
    "core_response = rq.get(api_call)\n",
    "\n",
    "# check the status code\n",
    "core_response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68763fe-1dad-4106-b5ee-36595db8f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell python to \"format\" this string of text as JSON. \n",
    "response_json = core_response.json()\n",
    "\n",
    "# Python will then save the info into what we call dictionary, which can then be loaded into a dataframe\n",
    "# note that if the structure of dictionary is a bit complicated, you may need to unravel it first. \n",
    "response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13784c01-0bdb-4d9c-bad0-5bf52a2e2ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting fulltext from a single HTML page\n",
    "\n",
    "Link to article used in this notebook: https://crl.acrl.org/index.php/crl/article/view/24753/32576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14fff5f-793f-4e62-a702-9b50dc19619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://crl.acrl.org/index.php/crl/article/view/24753/32576\"\n",
    "markup = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b081587-e6f3-4710-9ff6-1b99a5b3b6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse content\n",
    "soup = BeautifulSoup(markup, 'lxml') # with lxml parser\n",
    "# soup = BeautifulSoup(markup, 'html.parser') # with html5 parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431d992-2dcc-4297-a58b-8c8bb2be41c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full text content is located inside a \"div\" element inside div#content. \n",
    "# it's always placed as the first child and the only div without class\n",
    "# the CSS selector below will only work for ACRL full-text article pages.\n",
    "content = soup.select(\"div#content > div:not(.block)\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec3b7d-afb0-449f-a074-6396de0b20b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# go through the tags contained inside the retrieved div and apply the checks, etc.\n",
    "# print out the result\n",
    "fulltext = \"\"\n",
    "if (content):\n",
    "    for div in content:\n",
    "        for tag in div:\n",
    "            fulltext += tag.text + \"\\n\" #save everything inside this div regardless of tag type\n",
    "            if tag.name == \"h1\":\n",
    "                print(\"Title: \", tag.text)\n",
    "            elif tag.name == \"p\" or tag.name == \"ul\":\n",
    "                print(\"Text:\", tag.text)\n",
    "            elif tag.name == \"h2\" or tag.name == \"h3\": \n",
    "                print(\"Headings:\", tag.text)\n",
    "            elif tag.name == \"div\":\n",
    "                print(\"Tables:\", tag.text)\n",
    "else:\n",
    "    print(\"content is empty; please check the HTML tags for soup.select\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bb743-da75-498b-b16e-e403d4938113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "txt_file = open(\"crl_fulltext.txt\",\"w\", encoding='utf-8')\n",
    "txt_file.write(fulltext)\n",
    "txt_file.close() #to change file access modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81174e-338a-47dc-bc04-663664166e9d",
   "metadata": {},
   "source": [
    "Brief lecture on:\n",
    "* advantages of using API over webscraping\n",
    "* available APIs to use (show API guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edccb0c-6846-4adb-9918-3cf61e6d9e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text analysis 101 (30 mins)\n",
    "\n",
    "- The pre-processing\n",
    "- Descriptive text analysis: WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc9f3d-74bd-4ad1-aaa6-b1a0b6a61d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the JSON data, containing approx 200 articles from CORE\n",
    "core_df = pd.read_json(\"core_articles.json\")\n",
    "core_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18463643-f5bf-4f4f-a9dd-b263aad6cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are not interested in all the columns, so let's get only the necessary columns\n",
    "metadata_df = core_df[['createdDate', 'title', 'abstract', 'fullText', 'yearPublished']]\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79becdf0-123e-405b-acb6-1545eed3f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import nltk\n",
    "from nltk import word_tokenize #tokenizer\n",
    "from nltk.corpus import stopwords #stopwords\n",
    "from nltk.stem import WordNetLemmatizer #lemmatizer\n",
    "from nltk.probability import FreqDist #to count words\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a34f6-fcaf-4e51-8894-716874f60de6",
   "metadata": {},
   "source": [
    "**Goal: create a word cloud of the corpus to get an overview of the theme. Let's use the abstract for this exercise.**\n",
    "\n",
    "Preprocessing steps:\n",
    "* remove punctuations (remove non-alphanumeric characters)\n",
    "* convert to lowercase\n",
    "* tokenize the words\n",
    "* lemmatize the words\n",
    "* remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c37a37-d933-4c8c-b3d1-da4b9a637e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_abstract = \"\" # empty string to hold all of the abstracts in one variable\n",
    "\n",
    "# combine all the abstract contents into one string variable\n",
    "# while combining, do step #1 remove non-alphanumeric characters\n",
    "for abstract in metadata_df[\"abstract\"]:\n",
    "    if abstract:\n",
    "        temp_string = re.sub('[^a-zA-Z0-9]', ' ', str(abstract)) # cleanup the text from non alphanumeric characters.\n",
    "        all_abstract += str(temp_string)  #append the abstract content to all_abstract\n",
    "        \n",
    "all_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0c9f2-b811-42ba-b4e6-5a9666077f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #2 convert to lowercase\n",
    "all_abstract = all_abstract.lower()\n",
    "all_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a71e0-8e47-4ae0-8bd7-112b27f02e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #3 tokenize the words with NLTK's word_tokenize\n",
    "tokenized_abstract = word_tokenize(all_abstract)\n",
    "tokenized_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0145e2f-d6f7-43f8-a04f-4d6916895eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #4 lemmatize the words and Step #5 remove stopwords\n",
    "\n",
    "# prepare an empty list to hold all the filtered words\n",
    "filtered_abstract = []\n",
    "\n",
    "#initiate the lemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "#initiate list of stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#update stopwords to also include singapore\n",
    "stop_words.update([\"singapore\"])\n",
    "\n",
    "for word in tokenized_abstract:\n",
    "    #lemmatize the word to its dictionary form\n",
    "    word = wnl.lemmatize(word)\n",
    "    \n",
    "    #check if it's part of the stop_words\n",
    "    if word not in stop_words:\n",
    "        #extra checks if it's alphabetical and not a numeric word\n",
    "        if word.isalpha():\n",
    "            #if yes, add this word to the list of filtered_abstract\n",
    "            filtered_abstract.append(word)\n",
    "            \n",
    "filtered_abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb408f4-6acc-494c-b342-e573fd3762dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualizing the result through frequncy list or word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea345a39-7c95-4cba-8ba0-b541e418b30e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the exact count of occurence of the words using nltk's FreqDist\n",
    "fdist = FreqDist(filtered_abstract)\n",
    "print(\"Top 50 most used words in the abstract: \\n\")\n",
    "\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0844a7-4e21-4a41-9219-5e652fcec6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF ON WINDOWS: download the following pre-build \"wheel\" file from https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud \n",
    "# and use the following pip command\n",
    "\n",
    "!pip install wordcloud-1.8.1-cp39-cp39-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e8107-725b-400a-8ff9-097043414a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9efea7-2f7e-4aae-9f69-97fb1ed6ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87832fc5-7827-4f2a-aa40-445f972b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the list of string\n",
    "text = \" \".join(filtered_abstract)\n",
    "\n",
    "word_cloud = WordCloud(background_color = 'white', max_words=50, width=1200, height=800)\n",
    "word_cloud.generate(text)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edec6d1-f8e0-434b-b9a3-ce4e9d24adcb",
   "metadata": {},
   "source": [
    "Based on the result, you may need to adjust the stopwords to get more meaningful wordclouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0cfab2-4504-4c80-a96a-e4d64aaa3a35",
   "metadata": {},
   "source": [
    "***Try Yourself:***\n",
    "* Do the pre-processing on the full text instead of abstract. Do you get a different list of words?\n",
    "* Create a word cloud of papers published in 2016 vs 2017. Are there any differences?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
